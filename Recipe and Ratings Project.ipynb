{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80 Final Project\n",
    "\n",
    "**Name(s)**: Borui Lin, Junshu Xin\n",
    "\n",
    "**Website Link**: https://github.com/boruilin/Number-of-Step-and-Ratings-in-Recipe.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.652554Z",
     "start_time": "2019-10-31T23:36:27.180520Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from pathlib import Path\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer, OneHotEncoder, Binarizer\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "pd.options.plotting.backend = 'plotly'\n",
    "%matplotlib inline\n",
    "from dsc80_utils import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing the data csv\n",
    "recipe = '/Users/albertlin/Desktop/dsc80-2024-fa/projects/project04/food_data/RAW_recipes.csv'\n",
    "inter = '/Users/albertlin/Desktop/dsc80-2024-fa/projects/project04/food_data/RAW_interactions.csv'\n",
    "# Load the CSV file into a DataFrame\n",
    "recipes_data=pd.read_csv(recipe)\n",
    "inter_data=pd.read_csv(inter)\n",
    "# merging the data and replacing the 0s in ratings with nan\n",
    "rated_recipes = recipes_data.merge(inter_data, left_on = 'id', right_on = 'recipe_id', how = 'left').drop(columns=['id'])\n",
    "rated_recipes['rating'] = rated_recipes['rating'].replace(0, np.nan)\n",
    "#Adding a column for average rating\n",
    "average_rating = rated_recipes.groupby('recipe_id')['rating'].mean().reset_index()\n",
    "average_rating.rename(columns={'rating': 'average_rating'}, inplace=True)\n",
    "rated_recipes = rated_recipes.merge(average_rating, on = 'recipe_id', how = 'left')\n",
    "#Adding a boolean column indicating whether n_steps is larger than 9\n",
    "rated_recipes['high_step'] = rated_recipes['n_steps']>9\n",
    "\n",
    "\n",
    "#Histogram of Distribution of number of steps in recipes\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(recipes_data['n_steps'], bins=30, edgecolor='black', alpha=0.7)\n",
    "# plt.title('Histogram of Number of Steps in Recipes', fontsize=16)\n",
    "# plt.xlabel('Number of Steps', fontsize=14)\n",
    "# plt.ylabel('Frequency', fontsize=14)\n",
    "# plt.grid(axis='y', alpha=0.75)\n",
    "# plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_ingredients\n",
       "8     25553\n",
       "9     24716\n",
       "7     24406\n",
       "      ...  \n",
       "32        4\n",
       "33        1\n",
       "37        1\n",
       "Name: count, Length: 34, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=rated_recipes.columns[rated_recipes.isna().any()].tolist()\n",
    "y=rated_recipes['review'].isna().sum()\n",
    "rated_recipes['n_ingredients'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(0.04826454186632742), np.float64(0.06701035472139882))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs2, obs1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Assessment of Missingness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.04826454186632742)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find out the columns that contains missing values\n",
    "na_counts = rated_recipes.isna().sum()\n",
    "na_counts_in_cols_with_na = na_counts[na_counts > 0]\n",
    "\n",
    "# Filter for columns with at least one missing value\n",
    "na_counts_in_cols_with_na = na_counts[na_counts > 0]\n",
    "# The description column contains some missing values, the missing mechanism is mostly like NMAR\n",
    "rated_recipes['no description']=rated_recipes['description'].isna()\n",
    "rated_recipes['no rating']=rated_recipes['rating'].isna()\n",
    "rated_recipes['submitted'] = pd.to_datetime(rated_recipes['submitted'], errors='coerce')\n",
    "current_year = datetime.now().year\n",
    "rated_recipes['years_since_submission'] = current_year - rated_recipes['submitted'].dt.year\n",
    "\n",
    "# permutation test for determinig whether rating is MAR on n_steps\n",
    "stats1, obs1=permutation_test(rated_recipes, \"n_steps\",'no rating', ks)\n",
    "pval_1=np.mean(stats1>=obs1) \n",
    "# permutation test for determinig whether rating is MAR on years_since_submission\n",
    "stats2, obs2=permutation_test(rated_recipes, \"years_since_submission\",'no rating', tvd)\n",
    "pval_2=np.mean(stats2>=obs2) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# rating is MAR depended on n_steps, n_ingredients (diff_in_means), and years_since_submission (ks) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_step_dist_plot.html'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Graph for Distribution of Number of Steps by Missingness of Rating\n",
    "fig = create_kde_plotly(\n",
    "    rated_recipes,\n",
    "    group_col='no rating',\n",
    "    group1=True,\n",
    "    group2=False,\n",
    "    vals_col='n_steps',\n",
    "    title=\"Distribution of Number of Steps by Missingness of Rating\",\n",
    "    x_label=\"Number of Steps\",\n",
    "    y_label=\"Density\",\n",
    "    legend_title=\"Missing Rating\",\n",
    "    colors=['red', 'blue']\n",
    ")\n",
    "plotly.offline.plot(fig, filename='n_step_dist_plot.html', auto_open=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#_year_dist_plot.html'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Graph for Distribution of # Years Since Submission by Missingness of Rating\n",
    "fig = create_kde_plotly(\n",
    "    rated_recipes,\n",
    "    group_col='no rating',\n",
    "    group1=True,\n",
    "    group2=False,\n",
    "    vals_col='years_since_submission',\n",
    "    title=\"Distribution of # Years Since Submission by Missingness of Rating\",\n",
    "    x_label=\"Number of Years Since Submission\",\n",
    "    y_label=\"Density\",\n",
    "    legend_title=\"Missing Rating\",\n",
    "    colors=['red', 'blue']\n",
    ")\n",
    "plotly.offline.plot(fig, filename='#_year_dist_plot.html', auto_open=True) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_step_ks_plot.html'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KS Stats in Number of Step plot\n",
    "# Generate the histogram for the permutation test statistics\n",
    "fig = px.histogram(\n",
    "    pd.DataFrame(stats1, columns=[\"Permutation Statistic\"]),  # Convert stats to DataFrame\n",
    "    x=\"Permutation Statistic\", \n",
    "    nbins=50, \n",
    "    histnorm=\"probability\", \n",
    "    title=\"Custom Title for KS Statistic Distribution\"  # Set custom title here\n",
    ")\n",
    "\n",
    "# Add a vertical line for the observed statistic\n",
    "fig.add_vline(\n",
    "    x=obs1, \n",
    "    line_color=\"red\", \n",
    "    line_width=2, \n",
    "    opacity=1,\n",
    "    annotation_text=f\"Observed = {round(obs, 4)}\",\n",
    "    annotation_position=\"top right\"\n",
    ")\n",
    "\n",
    "# Adjust layout and axis ranges\n",
    "fig.update_layout(\n",
    "    xaxis_range=[0, 0.08],  # Adjusted range to match your desired shape\n",
    "    yaxis_range=[0, 0.12],  # Adjusted to maintain proportionality\n",
    "    xaxis_title=\"KS Statistic\",  # Set custom x-axis title\n",
    "    yaxis_title=\"Probability\",   # Set custom y-axis title\n",
    "    title=dict(\n",
    "        text=\"KS Distribution in Number of Steps\",  # Custom title\n",
    "        x=0.5,  # Center-align the title\n",
    "        xanchor=\"center\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plotly.offline.plot(fig, filename='n_step_ks_plot.html', auto_open=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'years_since_submission_tvd_plot.html'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TVD in Number of Step plot\n",
    "# Generate the histogram for the permutation test statistics\n",
    "fig = px.histogram(\n",
    "    pd.DataFrame(stats2, columns=[\"Permutation Statistic\"]),  # Convert stats to DataFrame\n",
    "    x=\"Permutation Statistic\", \n",
    "    nbins=50, \n",
    "    histnorm=\"probability\", \n",
    "    title=\"Custom Title for KS Statistic Distribution\"  # Set custom title here\n",
    ")\n",
    "\n",
    "# Add a vertical line for the observed statistic\n",
    "fig.add_vline(\n",
    "    x=obs2, \n",
    "    line_color=\"red\", \n",
    "    line_width=2, \n",
    "    opacity=1,\n",
    "    annotation_text=f\"Observed = {round(obs2, 4)}\",\n",
    "    annotation_position=\"top right\"\n",
    ")\n",
    "\n",
    "# Adjust layout and axis ranges\n",
    "fig.update_layout(\n",
    "    xaxis_range=[0, 0.08],  # Adjusted range to match your desired shape\n",
    "    yaxis_range=[0, 0.12],  # Adjusted to maintain proportionality\n",
    "    xaxis_title=\"TVD\",  # Set custom x-axis title\n",
    "    yaxis_title=\"Probability\",   # Set custom y-axis title\n",
    "    title=dict(\n",
    "        text=\"TVD Distribution in Years_Since_Submission\",  # Custom title\n",
    "        x=0.5,  # Center-align the title\n",
    "        xanchor=\"center\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "plotly.offline.plot(fig, filename='years_since_submission_tvd_plot.html', auto_open=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'n_step_ks_plot.html'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.005233659109012301), np.float64(0.0))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def permutation_test_diff_means(group1, group2, n_permutations=1000): \n",
    "    # Calculate the observed difference in means\n",
    "    observed_diff = np.mean(group1) - np.mean(group2)\n",
    "    \n",
    "    # Combine the data from both groups\n",
    "    combined = np.concatenate([group1, group2])\n",
    "    \n",
    "    # Initialize an array to store permuted differences\n",
    "    permuted_diffs = []\n",
    "    \n",
    "    # Perform permutations\n",
    "    for _ in range(n_permutations):\n",
    "        # Shuffle the combined data\n",
    "        np.random.shuffle(combined)\n",
    "        \n",
    "        # Split the shuffled data into two groups of the same sizes as the original groups\n",
    "        permuted_group1 = combined[:len(group1)]\n",
    "        permuted_group2 = combined[len(group1):]\n",
    "        \n",
    "        # Calculate the difference in means for the permuted data\n",
    "        permuted_diff = np.mean(permuted_group1) - np.mean(permuted_group2)\n",
    "        permuted_diffs.append(permuted_diff)\n",
    "    \n",
    "    # Calculate the p-value as the proportion of permuted differences\n",
    "    # that are as extreme as or more extreme than the observed difference\n",
    "    permuted_diffs = np.array(permuted_diffs)\n",
    "    p_value = np.mean(np.abs(permuted_diffs) >= np.abs(observed_diff))\n",
    "    \n",
    "    return observed_diff, p_value\n",
    "#  merge the recipe and the \n",
    "\n",
    "rated_recipes\n",
    "# Split into groups based on median\n",
    "median_n_steps = rated_recipes['n_steps'].median()\n",
    "rated_recipes['steps_group'] = np.where(rated_recipes['n_steps'] <= median_n_steps, 'low_steps', 'high_steps')\n",
    "low_steps=rated_recipes[rated_recipes['steps_group'] == 'low_steps']\n",
    "high_steps=rated_recipes[rated_recipes['steps_group'] == 'high_steps']\n",
    "# Extract ratings for the two groups\n",
    "low_steps_ratings =low_steps['average_rating']\n",
    "high_steps_ratings = high_steps['average_rating']\n",
    "observed_diff, p_value = permutation_test_diff_means(high_steps_ratings, low_steps_ratings)\n",
    "\n",
    "observed_diff, p_value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Framing a Prediction Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.657068Z",
     "start_time": "2019-10-31T23:36:28.654650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>minutes</th>\n",
       "      <th>contributor_id</th>\n",
       "      <th>submitted</th>\n",
       "      <th>...</th>\n",
       "      <th>years_since_submission</th>\n",
       "      <th>steps_group</th>\n",
       "      <th>for_large_group</th>\n",
       "      <th>has_fish</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 brownies in the world    best ever</td>\n",
       "      <td>40</td>\n",
       "      <td>985201</td>\n",
       "      <td>2008-10-27</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>high_steps</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 in canada chocolate chip cookies</td>\n",
       "      <td>45</td>\n",
       "      <td>1848091</td>\n",
       "      <td>2011-04-11</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>high_steps</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>412 broccoli casserole</td>\n",
       "      <td>40</td>\n",
       "      <td>50969</td>\n",
       "      <td>2008-05-30</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>low_steps</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234426</th>\n",
       "      <td>cookies by design   sugar shortbread cookies</td>\n",
       "      <td>20</td>\n",
       "      <td>506822</td>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>low_steps</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234427</th>\n",
       "      <td>cookies by design   sugar shortbread cookies</td>\n",
       "      <td>20</td>\n",
       "      <td>506822</td>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>low_steps</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234428</th>\n",
       "      <td>cookies by design   sugar shortbread cookies</td>\n",
       "      <td>20</td>\n",
       "      <td>506822</td>\n",
       "      <td>2008-04-15</td>\n",
       "      <td>...</td>\n",
       "      <td>16</td>\n",
       "      <td>low_steps</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>234429 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  minutes  contributor_id  \\\n",
       "0               1 brownies in the world    best ever       40          985201   \n",
       "1                 1 in canada chocolate chip cookies       45         1848091   \n",
       "2                             412 broccoli casserole       40           50969   \n",
       "...                                              ...      ...             ...   \n",
       "234426  cookies by design   sugar shortbread cookies       20          506822   \n",
       "234427  cookies by design   sugar shortbread cookies       20          506822   \n",
       "234428  cookies by design   sugar shortbread cookies       20          506822   \n",
       "\n",
       "        submitted  ... years_since_submission steps_group  for_large_group  \\\n",
       "0      2008-10-27  ...                     16  high_steps             True   \n",
       "1      2011-04-11  ...                     13  high_steps             True   \n",
       "2      2008-05-30  ...                     16   low_steps            False   \n",
       "...           ...  ...                    ...         ...              ...   \n",
       "234426 2008-04-15  ...                     16   low_steps             True   \n",
       "234427 2008-04-15  ...                     16   low_steps             True   \n",
       "234428 2008-04-15  ...                     16   low_steps             True   \n",
       "\n",
       "       has_fish  \n",
       "0         False  \n",
       "1         False  \n",
       "2         False  \n",
       "...         ...  \n",
       "234426    False  \n",
       "234427    False  \n",
       "234428    False  \n",
       "\n",
       "[234429 rows x 24 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "# We are attempting to predict the average rating using different columns (existing ones and the ones we encoded)\n",
    "rated_recipes['for_large_group'] = rated_recipes['tags'].str.contains('for-large-groups')\n",
    "rated_recipes['has_fish'] = rated_recipes['ingredients'].str.contains('fish')\n",
    "rated_recipes['submitted'] = pd.to_datetime(rated_recipes['submitted'], errors='coerce')\n",
    "current_year = datetime.now().year\n",
    "rated_recipes['years_since_submission'] = current_year - rated_recipes['submitted'].dt.year\n",
    "rated_recipes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score (Weighted): 0.5436764965306647\n",
      "Accuracy: 0.5715490325668315\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       154\n",
      "           2       0.00      0.00      0.00       239\n",
      "           3       0.00      0.00      0.00      1751\n",
      "           4       0.58      0.77      0.66     22759\n",
      "           5       0.56      0.40      0.47     18976\n",
      "\n",
      "    accuracy                           0.57     43879\n",
      "   macro avg       0.23      0.23      0.23     43879\n",
      "weighted avg       0.54      0.57      0.54     43879\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/albertlin/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/albertlin/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n",
      "/Users/albertlin/miniforge3/envs/dsc80/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning:\n",
      "\n",
      "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rated_recipes_filtered=rated_recipes.dropna(subset=['rating'])\n",
    "# Define features and target\n",
    "\n",
    "features = rated_recipes_filtered[['n_steps','minutes', 'years_since_submission']]  # Example numeric features\n",
    "target =rated_recipes_filtered['average_rating'].astype(int)  # Ratings as target classes (1-5)\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=50, max_depth=7, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "f1 = f1_score(y_test, predictions, average='weighted')  # Weighted for class imbalance\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "classification_rep = classification_report(y_test, predictions)\n",
    "\n",
    "print(f\"F1 Score (Weighted): {f1}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", classification_rep)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_f1 = 0\n",
    "# best_features = None\n",
    "# feature_columns = ['n_steps', 'minutes', 'n_ingredients', 'for_large_group',]\n",
    "# # Iterate over all combinations of two features\n",
    "# for feature_pair in combinations(feature_columns, 2):\n",
    "#     # Select the feature pair\n",
    "#     features = rated_recipes_filtered[list(feature_pair)]\n",
    "#     target = rated_recipes_filtered['average_rating'].astype(int)  # Use ratings as the target variable\n",
    "\n",
    "#     # Split the data\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # Train the model\n",
    "#     rf_classifier = RandomForestClassifier(n_estimators=20, max_depth=5, random_state=42)\n",
    "#     rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "#     # Predict on the test set\n",
    "#     predictions = rf_classifier.predict(X_test)\n",
    "\n",
    "#     # Calculate the F1 score\n",
    "#     f1 = f1_score(y_test, predictions, average='weighted')\n",
    "\n",
    "#     # Update the best F1 score and features if current F1 is better\n",
    "#     if f1 > best_f1:\n",
    "#         best_f1 = f1\n",
    "#         best_features = feature_pair\n",
    "\n",
    "# print(f\"Best F1 Score: {best_f1}\")\n",
    "# print(f\"Best Feature Pair: {best_features}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.662099Z",
     "start_time": "2019-10-31T23:36:28.660016Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Fairness Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-31T23:36:28.666489Z",
     "start_time": "2019-10-31T23:36:28.664381Z"
    }
   },
   "outputs": [],
   "source": [
    "# TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
